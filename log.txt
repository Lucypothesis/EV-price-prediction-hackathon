240115-pred01: 1.6061374658
- 배터리용량값 결측치 평균으로 채움
- 범주형 변수에 대해 레이블 인코딩을 적용

240115-pred02: 54.7710645129
- 가정: 배터리용량값 결측치 회귀모델 훈련해서 채움
- 상관계수 분석하여
    - train: '보증기간(년)', '가격(백만원)', '주행거리(km)', '차량상태_Pre-Owned'
    - test: '보증기간(년)', '주행거리(km)', '차량상태_Pre-Owned' 
- 결과: 54.7710645129

240116-pred04: 55.1427874689
- 차원이 너무 복잡해져서 오히려 점수가 줄어들었나?
- 가정: 상관계수 낮은 차원 삭제
- 실험: 가격과의 상관계수 계산, LightGBM 기반 변수 중요도 계산 -> 공통 feature 삭제
       공통 항목: ['사고이력', '모델_ID4', '모델_KNE', '구동방식_RWD', '모델_i5', '차량상태_Pre-Owned', '모델_MS', '연식(년)', '모델_iX']
- 결과: 55.1427874689 (???)

240116-pred05: 54.667309255
- 가정: 모두 레이블인코딩을 해보자 (원핫인코딩이 차원을 증가시킨다)
       그리고 배터리용량값 결측치 회귀모델 훈련할 때 train, test feature 통일시킴 ('보증기간(년)', 주행거리(km), '차량상태')
- 결과: 54.667309255 (????) -> 배터리용량값 결측치를 회귀모델 훈련해서 채운 게 문제인 것 같다

240116-pred06: 1.8172457961
- 가정: 배터리용량값 결측치를 전체를 삭제해서 돌려보자
- 결과: 1.8172457961 -> 배터리용량값 결측치는 단순한 방법으로 살려두는 게 맞다

240116-pred07: 1.500101965 !!!!
- 가정: 배터리용량값 결측치를 차량상태별 중앙값으로 채움
- 결과: 1.500101965 -> 차량상태별 중앙값으로 채우는 게 맞았음

240116-pred08: 1.667434377
- 가정: 배터리용량값 결측치를 차량상태별 평균값으로 채움
- 결과: 1.667434377 -> 차량상태별 중앙값으로 채우는 게 베스트

240116-pred09: 1.0876433662 !!!!
- 가정: 학습모델을 decision tree에서 다른거로 바꾸면 점수가 올라갈 것이다
- 실험: DecisionTree, RandomForest, GradientBoosting, LinearRegression, SVR, KNN, LightGBM, CatBoost, XGBoost
       비교 후 제일 성능 좋은 CatBoost(1.3845)로 설정
- 결과: 1.0876433662 -> CatBoost 모델 사용하니 성능이 많이 오름


240117-pred10: 0.9794726483	!!!
- 가정: 없음
- 실험: pred09와 같은 코드로 돌렸더니 LGBM이 RMSE 성능 가장 높게 나와서 이 값으로 제출해봄
- 결과: 0.9794726483	-> 같은 코드라도 돌릴 때마다 모델 성능이 다르게 나오는듯하다.

240118-pred11: 0.9451251291 !!!
- 가정: 세밀한 결측치 처리. 결측치 처리할 때 차량상태와 보증기간(년)의 4분위로 그룹을 나눠서 채우면 점수가 올라갈 것이다.
- 실험: 상관계수 분석 후 차량상태와 보증기간(년)을 고려한 그룹을 생성하기로 함
       중앙값으로 채움
- 결과: 0.9451251291 -> 역시 세밀한 결측치처리가 성능을 높임

240118-pred12: 1.0135202772
- 가정: pred11와 같은 방법이지만 결측치를 중앙값이 아니라 평균값으로 채움
- 결과: 1.0135202772 -> 역시 중앙값으로 채우는 게 잘 된다 (이유는 모름)

240118-pred13: 1.2320645267	
- 가정: pred11와 같은 방법이지만 보증기간(년)의 unique한 값들로 세세하게 그룹화해서 중앙값 채우는 게 성능이 높을 것이다
- 실험: 차량상태와 보증기간(년)의 unique한 값들로 중앙값은 채움
- 결과: 1.2320645267	-> 불확실한 상태에서 결측치를 너무 세세하게 채워버리면 오히려 성능이 떨어지는듯

240118-pred14: 0.9555834927
- 가정: 다른 변수와 상관관계가 낮은 열을 삭제하면 차원이 축소되어 성능이 오를 것이다.
- 실험: 상관관계 분석 후 '사고이력', '연식(년)' 열 삭제함
- 결과: 0.9555834927 -> 상관관계가 낮아도 넣어놓는 것이 좋겠다. 지금은 차원축소가 필요한 상황은 아닌가보다.

240118-pred15: 1.0163864823
- 가정: Optuna로 모델을 설정하고 하이퍼파라미터튜닝을 하면 성능이 오를 것이다.
- 실험: Optuna로 LGBM의 하이퍼파라미터 찾아서 예측값 추출함
- 결과: 1.0163864823 -> 흠 그냥 돌렸을 때가 낫다 ????? 다르게 찾아봐야할듯

250125-pred16: 0.9360308428 !!!
- 생각의 흐름
       Train 데이터 중 Brand New이면서 사고이력 Yes는 무엇인가??
       Test에도 Brand New이면서 사고이력이 Yes인 값들이 있나?
              - 들어있음.. 이것을 어떻게 해석할 것인가
              - Brand New의 정의가 단순히 **공장에서 출고된 새 차량**이 아니라, **판매 전 차량**을 포함할 수 있음
              - 판매 전 차량은 전시, 테스트주행, 운송거리 등으로 인해서 주행거리가 기록될 수 있음
       도메인 지식이 중요하긴 한 것 같다.
- 가정: 파생변수를 추가하면 성능이 오를 것이다.
- 실험: Brand New이면서 사고이력이 Yes인 것에 대한 파생변수를 추가함(BrandNew_Accident)
- 결과: 0.9360308428 -> 일단 지금은 파생변수가 더 필요한 상황임을 알 수 있음

250127-pred17: 0.9360308428
- 가정: 파생변수를 더 추가하면 성능이 오를 것이다.
- 실험: 원핫인코딩 후, 각각의 변수에 대한 상관관계 분석 후 유의미한 파생변수 2개를 추출함
       B_RWD (제조사가 'B사'이고 구동방식이 'RWD'인 것들을 1, 나머지를 0)
- 결과: 0.9360308428 -> B_RWD가 전혀 영향을 미치지 못했다 ..

250127-pred18: 0.9360308428
- 가정: 주행거리(km)을 로그변환하면 성능이 올라갈 것이다.
- 실험: 주행거리(km)에 로그변환 적용함
- 결과: 0.9360308428 -> 찾아보니 트리기반모델(XGBoost, LightGBM, Random Forest 등)은
                       데이터를 자동으로 구간화해서 비선형 관계도 잘 학습한다고 한다.
                       이런 모델에서는 로그 변환으로 데이터를 선형화할 필요가 적기 때문에, 성능이 같게 나올 수 있다.
                    -> 결론: 로그변환은 의미가 없음

250127-pred19: 
- 가정: 파생변수를 더 추가하면 성능이 오를 것이다.
- 실험: 원핫인코딩 후 상관관계 분석을 기반으로 파생변수를 여러 개 생성하여 모델 돌린 후 feature importance 분석하여
       zero-importance인 열들 삭제 후 다시 모델 학습
- 결과: 

250127-pred20: 
- 가정: 파생변수를 더 추가하면 성능이 오를 것이다.
- 실험: 원핫인코딩 후 상관관계 분석을 기반으로 파생변수를 여러 개 생성하여 모델 돌린 후 feature importance 분석하여
       zero-importance인 열들과 
- 결과: 

250127-pred21: 
- 가정: 파생변수를 더 추가하면 성능이 오를 것이다.
- 실험: 원핫인코딩 후 상관관계 분석을 기반으로 파생변수를 여러 개 생성하여 모델 돌린 후 feature importance 분석하여
       zero-importance인 열들 삭제 후 다시 모델 학습
- 결과: 


- 파생변수 더 추가
- 예측 모델 가지고 이상치 탐지하기